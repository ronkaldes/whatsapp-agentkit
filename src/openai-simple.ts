import OpenAI from "openai";
import dotenv from 'dotenv';

// Carrega vari√°veis de ambiente
dotenv.config();

// Configura√ß√£o do cliente OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Interface para resposta da OpenAI
 */
export interface OpenAIResponse {
  text: string;
  success: boolean;
  error?: string;
}

/**
 * Interface para hist√≥rico de conversa
 */
export interface ConversationMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

/**
 * Interface para contexto da conversa
 */
export interface ConversationContext {
  chatId: string;
  contactName: string;
  timestamp: string;
  platform: string;
  messageType: string;
  isGroup: boolean;
}

/**
 * Executa um workflow do AgentKit/ChatKit usando a API da OpenAI
 * @param workflowId - ID do Workflow (wf_xxx)
 * @param userInput - Input do usu√°rio
 * @param context - Contexto adicional para o workflow
 * @param conversationHistory - Hist√≥rico da conversa
 * @returns Promise<OpenAIResponse>
 */
export async function runAgentKitWorkflow(
  workflowId: string,
  userInput: string,
  context?: ConversationContext,
  conversationHistory?: ConversationMessage[]
): Promise<OpenAIResponse> {
  try {
    // Monta as mensagens incluindo contexto e hist√≥rico
    const messages: ConversationMessage[] = [
      {
        role: "system",
        content: `Voc√™ √© um assistente √∫til do AgentKit. Execute o workflow ${workflowId} conforme solicitado pelo usu√°rio.

Contexto da conversa:
- Contato: ${context?.contactName || 'Usu√°rio'}
- Plataforma: ${context?.platform || 'whatsapp'}
- Tipo de mensagem: ${context?.messageType || 'text'}
- √â grupo: ${context?.isGroup ? 'Sim' : 'N√£o'}
- Timestamp: ${context?.timestamp || new Date().toISOString()}

Instru√ß√µes:
- Seja amig√°vel e prestativo
- Mantenha respostas concisas (m√°ximo 500 caracteres para WhatsApp)
- Use emojis ocasionalmente para tornar a conversa mais amig√°vel
- Se for uma pergunta sobre AgentKit, responda com informa√ß√µes relevantes
- Se n√£o souber algo, seja honesto e ofere√ßa ajuda de outra forma
- Responda sempre em portugu√™s brasileiro

Contexto adicional: ${JSON.stringify(context || {})}`
      },
      ...(conversationHistory || []),
      {
        role: "user",
        content: userInput
      }
    ];

    console.log(`ü§ñ Executando workflow ${workflowId}...`);

    // Chama a API do ChatKit/AgentKit via chat completions
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: messages,
      temperature: 0.7,
      max_tokens: 500
    });

    const responseText = response.choices[0]?.message?.content || "Desculpe, n√£o consegui processar sua solicita√ß√£o.";

    console.log(`‚úÖ Resposta recebida do workflow`);

    return {
      text: responseText,
      success: true
    };

  } catch (error) {
    console.error(`‚ùå Erro ao executar workflow ${workflowId}:`, error);
    return {
      text: "Desculpe, ocorreu um erro ao processar sua solicita√ß√£o.",
      success: false,
      error: (error as Error).message
    };
  }
}

/**
 * Envia uma mensagem para a OpenAI e recebe uma resposta (fun√ß√£o simplificada)
 * @param message - Mensagem do usu√°rio
 * @param context - Contexto da conversa
 * @param conversationHistory - Hist√≥rico da conversa
 * @returns Promise<OpenAIResponse>
 */
export async function sendMessageToOpenAI(
  message: string,
  context: ConversationContext,
  conversationHistory: ConversationMessage[] = []
): Promise<OpenAIResponse> {
  // Usar o workflow padr√£o
  const defaultWorkflowId = process.env.WORKFLOW_ID || "wf_2V0vUNR8UYZ3xM15B9a910586940994955"; // ID do workflow do seu projeto
  return await runAgentKitWorkflow(defaultWorkflowId, message, context, conversationHistory);
}

/**
 * Cria um contexto padr√£o para conversas
 * @param chatId - ID do chat
 * @param contactName - Nome do contato
 * @param messageType - Tipo da mensagem
 * @param isGroup - Se √© um grupo
 * @returns ConversationContext
 */
export function createConversationContext(
  chatId: string,
  contactName: string,
  messageType: string,
  isGroup: boolean = false
): ConversationContext {
  return {
    chatId,
    contactName,
    timestamp: new Date().toISOString(),
    platform: 'whatsapp',
    messageType,
    isGroup
  };
}

/**
 * Limita o hist√≥rico de conversa para evitar tokens excessivos
 * @param history - Hist√≥rico atual
 * @param maxLength - Tamanho m√°ximo (padr√£o: 20)
 * @returns ConversationMessage[]
 */
export function limitConversationHistory(
  history: ConversationMessage[],
  maxLength: number = 20
): ConversationMessage[] {
  if (history.length <= maxLength) {
    return history;
  }
  
  // Mant√©m a mensagem do sistema e as √∫ltimas mensagens
  const systemMessage = history.find(msg => msg.role === 'system');
  const recentMessages = history.slice(-maxLength + 1);
  
  return systemMessage ? [systemMessage, ...recentMessages] : recentMessages;
}

/**
 * Testa a conex√£o com a OpenAI
 * @returns Promise<boolean>
 */
export async function testOpenAIConnection(): Promise<boolean> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: "Teste de conex√£o" }],
      max_tokens: 10
    });
    
    return response.choices[0]?.message?.content ? true : false;
  } catch (error) {
    console.error('Erro ao testar conex√£o com OpenAI:', error);
    return false;
  }
}
