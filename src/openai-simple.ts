import OpenAI from "openai";
import dotenv from 'dotenv';

// Carrega vari√°veis de ambiente
dotenv.config();

// Configura√ß√£o do cliente OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Interface para resposta da OpenAI
 */
export interface OpenAIResponse {
  text: string;
  success: boolean;
  error?: string;
}

/**
 * Interface para hist√≥rico de conversa
 */
export interface ConversationMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

/**
 * Interface para contexto da conversa
 */
export interface ConversationContext {
  chatId: string;
  contactName: string;
  timestamp: string;
  platform: string;
  messageType: string;
  isGroup: boolean;
}

// Armazena threads por chat ID
const chatThreads = new Map<string, string>();

/**
 * Executa um workflow do AgentKit usando OpenAI Assistants API
 * @param assistantId - ID do Assistant/Workflow
 * @param userInput - Input do usu√°rio
 * @param context - Contexto adicional para o workflow
 * @param conversationHistory - Hist√≥rico da conversa (n√£o usado com Assistants)
 * @returns Promise<OpenAIResponse>
 */
export async function runAgentKitWorkflow(
  assistantId: string,
  userInput: string,
  context?: ConversationContext,
  conversationHistory?: ConversationMessage[]
): Promise<OpenAIResponse> {
  try {
    const chatId = context?.chatId || 'default';

    // Obt√©m ou cria thread para este chat
    let threadId = chatThreads.get(chatId);

    if (!threadId) {
      console.log(`üîß Criando nova thread para chat ${chatId}`);
      const thread = await openai.beta.threads.create();
      threadId = thread.id;
      chatThreads.set(chatId, threadId);
    }

    // Adiciona contexto √† mensagem se dispon√≠vel
    let messageContent = userInput;
    if (context) {
      messageContent = `${userInput}\n\n[Contexto: Contato=${context.contactName}, Plataforma=${context.platform}]`;
    }

    // Adiciona mensagem do usu√°rio √† thread
    await openai.beta.threads.messages.create(threadId, {
      role: "user",
      content: messageContent
    });

    // Executa o assistant e aguarda conclus√£o
    console.log(`ü§ñ Executando assistant ${assistantId}...`);
    const run = await openai.beta.threads.runs.createAndPoll(threadId, {
      assistant_id: assistantId
    });

    if (run.status !== 'completed') {
      throw new Error(`Run ${run.status}: ${run.last_error?.message || 'Unknown error'}`);
    }

    // Obt√©m as mensagens da thread
    const messages = await openai.beta.threads.messages.list(threadId, {
      limit: 1,
      order: 'desc'
    });

    const lastMessage = messages.data[0];
    if (!lastMessage || lastMessage.role !== 'assistant') {
      throw new Error('Nenhuma resposta do assistant');
    }

    // Extrai o texto da resposta
    const textContent = lastMessage.content.find(c => c.type === 'text');
    const responseText = textContent && 'text' in textContent
      ? textContent.text.value
      : "Desculpe, n√£o consegui processar sua solicita√ß√£o.";

    console.log(`‚úÖ Resposta recebida do assistant`);

    return {
      text: responseText,
      success: true
    };

  } catch (error) {
    console.error(`‚ùå Erro ao executar assistant ${assistantId}:`, error);
    return {
      text: "Desculpe, ocorreu um erro ao processar sua solicita√ß√£o com o assistant.",
      success: false,
      error: (error as Error).message
    };
  }
}

/**
 * Limpa a thread de um chat espec√≠fico
 * @param chatId - ID do chat
 */
export function clearChatThread(chatId: string): void {
  chatThreads.delete(chatId);
  console.log(`üóëÔ∏è Thread do chat ${chatId} removida`);
}

/**
 * Envia uma mensagem para a OpenAI e recebe uma resposta (fun√ß√£o simplificada)
 * @param message - Mensagem do usu√°rio
 * @param context - Contexto da conversa
 * @param conversationHistory - Hist√≥rico da conversa
 * @returns Promise<OpenAIResponse>
 */
export async function sendMessageToOpenAI(
  message: string,
  context: ConversationContext,
  conversationHistory: ConversationMessage[] = []
): Promise<OpenAIResponse> {
  // Usar o workflow padr√£o
  const defaultWorkflowId = process.env.WORFLOW_ID || "wf_2V0vUNR8UYZ3xM15B9a910586940994955"; // ID do workflow do seu projeto
  return await runAgentKitWorkflow(defaultWorkflowId, message, context, conversationHistory);
}

/**
 * Cria um contexto padr√£o para conversas
 * @param chatId - ID do chat
 * @param contactName - Nome do contato
 * @param messageType - Tipo da mensagem
 * @param isGroup - Se √© um grupo
 * @returns ConversationContext
 */
export function createConversationContext(
  chatId: string,
  contactName: string,
  messageType: string,
  isGroup: boolean = false
): ConversationContext {
  return {
    chatId,
    contactName,
    timestamp: new Date().toISOString(),
    platform: 'whatsapp',
    messageType,
    isGroup
  };
}

/**
 * Limita o hist√≥rico de conversa para evitar tokens excessivos
 * @param history - Hist√≥rico atual
 * @param maxLength - Tamanho m√°ximo (padr√£o: 20)
 * @returns ConversationMessage[]
 */
export function limitConversationHistory(
  history: ConversationMessage[],
  maxLength: number = 20
): ConversationMessage[] {
  if (history.length <= maxLength) {
    return history;
  }
  
  // Mant√©m a mensagem do sistema e as √∫ltimas mensagens
  const systemMessage = history.find(msg => msg.role === 'system');
  const recentMessages = history.slice(-maxLength + 1);
  
  return systemMessage ? [systemMessage, ...recentMessages] : recentMessages;
}

/**
 * Testa a conex√£o com a OpenAI
 * @returns Promise<boolean>
 */
export async function testOpenAIConnection(): Promise<boolean> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: "Teste de conex√£o" }],
      max_tokens: 10
    });
    
    return response.choices[0]?.message?.content ? true : false;
  } catch (error) {
    console.error('Erro ao testar conex√£o com OpenAI:', error);
    return false;
  }
}
